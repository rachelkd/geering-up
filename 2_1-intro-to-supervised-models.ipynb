{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLR_sYAnfGWM"
   },
   "source": [
    "## Setup stuff (don't edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlV9JkDS9d9C"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "J_hCW-xZgZKp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs, make_classification, make_circles, make_moons, make_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZ7WlpCVlURO"
   },
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iRDAYN7PfY8Y"
   },
   "outputs": [],
   "source": [
    "num_data_points = 400\n",
    "\n",
    "moons_data = make_moons(n_samples=num_data_points, noise=0.2, random_state=42)\n",
    "\n",
    "classification_data = make_classification(n_samples=num_data_points, n_features=2,\n",
    "                                          n_informative=2, n_redundant=0,\n",
    "                                          class_sep=1,\n",
    "                                          n_clusters_per_class=1,\n",
    "                                          n_classes=2, random_state=42)\n",
    "\n",
    "blobs_data = make_blobs(n_samples=num_data_points, centers=3, cluster_std=3,\n",
    "                        n_features=2, random_state=42)\n",
    "\n",
    "circle_data = make_circles(n_samples=num_data_points, factor=0.5, noise=0.1,\n",
    "                           random_state=42)\n",
    "\n",
    "datasets = [moons_data, classification_data, blobs_data, circle_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4jq0CmplXD4"
   },
   "source": [
    "### Model Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqHzayNQhfNg"
   },
   "outputs": [],
   "source": [
    "def linear_model(c):\n",
    "  return LogisticRegression(C=c, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vKItjQYsibFi"
   },
   "outputs": [],
   "source": [
    "def linear_model_complex(c):\n",
    "  return SVC(kernel=\"linear\", C=c, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LI32DFORigK0"
   },
   "outputs": [],
   "source": [
    "def tree_model(depth):\n",
    "  return DecisionTreeClassifier(max_depth=depth, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3ADqjvWin_H"
   },
   "outputs": [],
   "source": [
    "def non_linear(neighbours):\n",
    "  return KNeighborsClassifier(n_neighbors=neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mnIlISUjCOx"
   },
   "outputs": [],
   "source": [
    "def non_linear_complex(gamma, c):\n",
    "  return SVC(kernel=\"rbf\", gamma=gamma, C=c, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arJ8mn0Flc6W"
   },
   "source": [
    "### Data Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "g9BVYdDKlfgg"
   },
   "outputs": [],
   "source": [
    "# Visualize data as a scatter plot\n",
    "def visualize_data(data):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    X, y = data\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', s=50, edgecolor='k')\n",
    "    ax.set_xlabel(\"Feature 1\", fontsize=12)\n",
    "    ax.set_ylabel(\"Feature 2\", fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ST19pw6o1sHz"
   },
   "outputs": [],
   "source": [
    "# Visualize feature boundary in scatter plot\n",
    "def visualize_boundary(X, y):\n",
    "    # Show decision boundaries\n",
    "    y_pred = model.predict(X)\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "\n",
    "\n",
    "    # Plot decision boundary and points\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot decision boundary\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, cmap=\"viridis\")\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', s=50, edgecolor='k')\n",
    "    ax.set_title(f\"Accuracy: {acc:.2f}\")\n",
    "    ax.set_xlabel(\"Feature 1\", fontsize=12)\n",
    "    ax.set_ylabel(\"Feature 2\", fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdQVwl-uJWHF"
   },
   "source": [
    "# Section 1: The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've created 4 interestingly-shaped datasets for you: `moons_data`, `classification_data`, `blobs_data`, and `circle_data`. Use the `visualize_data` function provided above to display each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the visualize_data function to show what each dataset looks like.\n",
    "#\n",
    "# HINT: If the code is not working make sure you have run all the cells above!\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Splitting The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what one of these datasets actually looks like and print out `moons_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment the line below to display moons_data\n",
    "# moons_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we notice? We have a tuple (pair of two items) with two arrays (lists) inside it. The first list stores sub-lists of length 2, and the second list has a bunch of 1s and 0s in it. \n",
    "\n",
    "Which list do you think is the features and which do you think is the target? Uncomment the appropriate line of code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment the appropriate line of code\n",
    "# If you think the first list holds the features and the second list holds the target, uncomment this line of code:\n",
    "# X, y = moons_data\n",
    "\n",
    "# If you think the first list holds the target and the second list holds the features, uncomment this line of code:\n",
    "# y, X = moons_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split the data into training and test sets, we use the `train_test_split` function. Use [this documentation link](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to get familiar with `train_test_split`. Scroll down on the page to see examples of the function being used in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split moons_data into train and test sets. Use a random state of 123. 30% of the data should be in the test set\n",
    "# Then print out X_train and y_train below\n",
    "#\n",
    "# HINT: Make sure that your X_train, X_test... etc variables are in the right order\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Test case (DO NOT EDIT)\n",
    "assert len(X_train) + len(X_test) == len(X), \"Expected X_train and X_test to combine to X\"\n",
    "assert len(y_train) + len(y_test) == len(y), \"Expected y_train and y_test to combine to y\"\n",
    "assert len(X_train) == len(X)*0.7, \"Expected X_train to be 70% of X's size, got \" + str(100*len(X_train)/len(X)) + \"%\"\n",
    "assert len(X_test) == len(X)*0.3, \"Expected X_test to be 30% of X's size, got \" + str(100*len(X_test)/len(X)) + \"%\"\n",
    "assert len(y_train) == len(y)*0.7, \"Expected y_train to be 70% of y's size, got \" + str(100*len(y_train)/len(y)) + \"%\"\n",
    "assert len(y_test) == len(y)*0.3, \"Expected y_test to be 30% of y's size, got \" + str(100*len(y_test)/len(y)) + \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: The Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out some models to see "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMbb3HehfNfS"
   },
   "source": [
    "### Tree Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kdy5xppjfVtR"
   },
   "outputs": [],
   "source": [
    "depth = 2\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "\n",
    "# use .fit(training data)\n",
    "\n",
    "# use .predict(testing data),\n",
    "\n",
    "# call the function visualize_boundary with the result of the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UdEQn6NJF5JA"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# plot_tree(model, feature_names=[\"Feature 1\", \"Feature 2\"], class_names=[\"Purple\", \"Yellow\"], label=\"none\", filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diTYJdWxMyDl"
   },
   "source": [
    "### Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWQ3kZjM9CTL"
   },
   "outputs": [],
   "source": [
    "X, y = classification_data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "c = 1\n",
    "\n",
    "model = LogisticRegression(C=c, random_state=42)\n",
    "\n",
    "# use .fit(training data)\n",
    "\n",
    "# use .predict(testing data),\n",
    "\n",
    "# call the functionisualize_boundary with the result of the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RuvcTxIX1kVz"
   },
   "outputs": [],
   "source": [
    "X, y = classification_data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "c = 1\n",
    "\n",
    "model = SVC(kernel=\"linear\", C=c, random_state=42)\n",
    "\n",
    "# use .fit(training data)\n",
    "\n",
    "# use .predict(testing data),\n",
    "\n",
    "# call the functionisualize_boundary with the result of the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdjFxIfEfP7_"
   },
   "source": [
    "### Non-Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LC54Ka8b5H1v"
   },
   "outputs": [],
   "source": [
    "X, y = circle_data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "g = 0.1\n",
    "c = 1\n",
    "\n",
    "model = SVC(kernel=\"rbf\", gamma=g, C=c, random_state=42)\n",
    "\n",
    "# use .fit(training data)\n",
    "\n",
    "# use .predict(testing data),\n",
    "\n",
    "# call the functionisualize_boundary with the result of the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sU92BTUTfWJ6"
   },
   "outputs": [],
   "source": [
    "X, y = blobs_data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "# Heads up! This model takes a long time to run (you will learn more about why tomorrow)\n",
    "# Suggestion: run once all your other models are done\n",
    "\n",
    "neighbours = 5\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=neighbours)\n",
    "\n",
    "# use .fit(training data)\n",
    "\n",
    "# use .predict(testing data),\n",
    "\n",
    "# call the functionisualize_boundary with the result of the prediction"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "MLR_sYAnfGWM",
    "SlV9JkDS9d9C",
    "TZ7WlpCVlURO",
    "arJ8mn0Flc6W",
    "owI1bnnLe5yj",
    "HdjFxIfEfP7_",
    "_2jmJi8k-TA1",
    "41-VYO65-XdM",
    "a-E0-UTX-ZZt",
    "-IlIkO6v-bO3",
    "mH2r5fGle1yF",
    "bLEoUgL1MOKi",
    "MS93VIQaMyP3"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330] *",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
