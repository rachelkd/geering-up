{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLR_sYAnfGWM",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup stuff (don't edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlV9JkDS9d9C"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_hCW-xZgZKp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs, make_classification, make_circles, make_moons, make_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZ7WlpCVlURO"
   },
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRDAYN7PfY8Y"
   },
   "outputs": [],
   "source": [
    "num_data_points = 400\n",
    "\n",
    "moons_data = make_moons(n_samples=num_data_points, noise=0.2, random_state=42)\n",
    "\n",
    "classification_data = make_classification(n_samples=num_data_points, n_features=2,\n",
    "                                          n_informative=2, n_redundant=0,\n",
    "                                          class_sep=1,\n",
    "                                          n_clusters_per_class=1,\n",
    "                                          n_classes=2, random_state=42)\n",
    "\n",
    "blobs_data = make_blobs(n_samples=num_data_points, centers=3, cluster_std=3,\n",
    "                        n_features=2, random_state=42)\n",
    "\n",
    "circle_data = make_circles(n_samples=num_data_points, factor=0.5, noise=0.1,\n",
    "                           random_state=42)\n",
    "\n",
    "datasets = [moons_data, classification_data, blobs_data, circle_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arJ8mn0Flc6W"
   },
   "source": [
    "### Data Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9BVYdDKlfgg"
   },
   "outputs": [],
   "source": [
    "# Visualize data as a scatter plot\n",
    "def visualize_data(data):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    X, y = data\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', s=50, edgecolor='k')\n",
    "    ax.set_xlabel(\"Feature 1\", fontsize=12)\n",
    "    ax.set_ylabel(\"Feature 2\", fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ST19pw6o1sHz"
   },
   "outputs": [],
   "source": [
    "# Visualize feature boundary in scatter plot\n",
    "def visualize_boundary(X, y, model, acc):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot decision boundary\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, cmap=\"viridis\")\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', s=50, edgecolor='k')\n",
    "    ax.set_title(f\"Accuracy: {acc:.2f}\")\n",
    "    ax.set_xlabel(\"Feature 1\", fontsize=12)\n",
    "    ax.set_ylabel(\"Feature 2\", fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdQVwl-uJWHF"
   },
   "source": [
    "# Section 1: The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've created 4 interestingly-shaped datasets for you: `moons_data`, `classification_data`, `blobs_data`, and `circle_data`. Use the `visualize_data` function provided above to display each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the visualize_data function to show what each dataset looks like.\n",
    "#\n",
    "# HINT: If the code is not working make sure you have run all the cells above!\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Splitting The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what one of these datasets actually looks like and print out `moons_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment the line below to display moons_data\n",
    "# moons_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we notice? We have a tuple (pair of two items) with two arrays (lists) inside it. The first list stores sub-lists of length 2, and the second list has a bunch of 1s and 0s in it. \n",
    "\n",
    "Which list do you think is the features and which do you think is the target? Uncomment the appropriate line of code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment the appropriate line of code\n",
    "# If you think the first list holds the features and the second list holds the target, uncomment this line of code:\n",
    "# X, y = moons_data\n",
    "\n",
    "# If you think the first list holds the target and the second list holds the features, uncomment this line of code:\n",
    "# y, X = moons_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split the data into training and test sets, we use the `train_test_split` function. Use [this documentation link](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to get familiar with `train_test_split`. Scroll down on the page to see examples of the function being used in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split moons_data into train and test sets. Use a random state of 123. 30% of the data should be in the test set\n",
    "# Then print out X_train and y_train below\n",
    "#\n",
    "# HINT: Make sure that your X_train, X_test... etc variables are in the right order\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Test case (DO NOT EDIT)\n",
    "assert len(X_train) + len(X_test) == len(X), \"Expected X_train and X_test to combine to X\"\n",
    "assert len(y_train) + len(y_test) == len(y), \"Expected y_train and y_test to combine to y\"\n",
    "assert len(X_train) == len(X)*0.7, \"Expected X_train to be 70% of X's size, got \" + str(100*len(X_train)/len(X)) + \"%\"\n",
    "assert len(X_test) == len(X)*0.3, \"Expected X_test to be 30% of X's size, got \" + str(100*len(X_test)/len(X)) + \"%\"\n",
    "assert len(y_train) == len(y)*0.7, \"Expected y_train to be 70% of y's size, got \" + str(100*len(y_train)/len(y)) + \"%\"\n",
    "assert len(y_test) == len(y)*0.3, \"Expected y_test to be 30% of y's size, got \" + str(100*len(y_test)/len(y)) + \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: The Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out some models to see which ones work best on the `moons_data` dataset. \n",
    "### Tree-Based Models\n",
    "Use [this documentation link](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) to familiarize yourself with `DecisionTreeClassifier` and try it out. Scroll down to see how to use `fit` and `score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kdy5xppjfVtR"
   },
   "outputs": [],
   "source": [
    "# TODO: Create a DecisionTreeClassifier, fit it to the training data, and score it with the testing data. Use a random state of 42\n",
    "#\n",
    "# HINT: Don't forget to modify the hyperparameter(s)! Play with them to see if you can find the best value for each.\n",
    "# HINT: If your code isn't working because of an array reshaping issue, you might have picked the wrong order for X and y in moons_data! \n",
    "#       Try changing that and running this cell again.\n",
    "#\n",
    "\n",
    "tree_model = ...\n",
    "\n",
    "# use .fit(training data)\n",
    "# ...\n",
    "\n",
    "# use .score(testing data)\n",
    "tree_score = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment the code below to display the decision boundary\n",
    "# visualize_boundary(X_test, y_test, tree_model, tree_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UdEQn6NJF5JA"
   },
   "outputs": [],
   "source": [
    "# TODO: Uncomment the code below to display the tree\n",
    "# plot_tree(tree_model, feature_names=[\"Feature 1\", \"Feature 2\"], class_names=[\"Purple\", \"Yellow\"], label=\"none\", filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diTYJdWxMyDl"
   },
   "source": [
    "### Linear Models\n",
    "Use [this documentation link](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) to familiarize yourself with `LogisticRegression` and try it out. Scroll down to see how to use `fit` and `score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWQ3kZjM9CTL"
   },
   "outputs": [],
   "source": [
    "# TODO: Create a LogisticRegression model, fit it to the training data, and score it with the testing data. Use a random state of 42\n",
    "#\n",
    "# HINT: Don't forget to modify the hyperparameter(s)! Play with them to see if you can find the best value for each.\n",
    "# HINT: If your code isn't working because of an array reshaping issue, you might have picked the wrong order for X and y in moons_data! \n",
    "#       Try changing that and running this cell again.\n",
    "#\n",
    "\n",
    "lr_model = ...\n",
    "\n",
    "# use .fit(training data)\n",
    "# ...\n",
    "\n",
    "# use .score(testing data)\n",
    "lr_score = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment the code below to display the decision boundary\n",
    "# visualize_boundary(X_test, y_test, lr_model, lr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdjFxIfEfP7_"
   },
   "source": [
    "### Non-Linear Models\n",
    "Use [this documentation link](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) to familiarize yourself with `SVC` (SVM RBF) and try it out. You can also try setting the kernel to `linear` to try out Linear SVM. Scroll down to see how to use `fit` and `score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LC54Ka8b5H1v"
   },
   "outputs": [],
   "source": [
    "# TODO: Create a SVM RBF model, fit it to the training data, and score it with the testing data. Use a random state of 42\n",
    "#\n",
    "# HINT: Don't forget to modify the hyperparameter(s)! Play with them to see if you can find the best value for each.\n",
    "# HINT: If your code isn't working because of an array reshaping issue, you might have picked the wrong order for X and y in moons_data! \n",
    "#       Try changing that and running this cell again.\n",
    "#\n",
    "\n",
    "svc_model = ...\n",
    "\n",
    "# use .fit(training data)\n",
    "# ...\n",
    "\n",
    "# use .score(testing data)\n",
    "svc_score = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment the code below to display the decision boundary\n",
    "# This will take a minute to run - this is normal!\n",
    "# visualize_boundary(X_test, y_test, svc_model, svc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [this documentation link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) to familiarize yourself with `KNeighborsClassifier` (K-Nearest Neighbours) and try it out. Scroll down to see how to use `fit` and `score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sU92BTUTfWJ6"
   },
   "outputs": [],
   "source": [
    "# TODO: Create a KNeighborsClassifier, fit it to the training data, and score it with the testing data\n",
    "#\n",
    "# HINT: Don't forget to modify the hyperparameter(s)! Play with them to see if you can find the best value for each.\n",
    "# HINT: If your code isn't working because of an array reshaping issue, you might have picked the wrong order for X and y in moons_data! \n",
    "#       Try changing that and running this cell again.\n",
    "# HINT: Make sure you're using the American spelling of \"neighbors\"\n",
    "#\n",
    "\n",
    "knn_model = ...\n",
    "\n",
    "# use .fit(training data)\n",
    "# ...\n",
    "\n",
    "# use .score(testing data)\n",
    "knn_score = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment the code below to display the decision boundary\n",
    "# This will take a minute to run - this is normal!\n",
    "# visualize_boundary(X_test, y_test, knn_model, knn_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Picking a Good Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have noticed that, no matter how much you change the hyperparameters for a model, sometimes the model just doesn't fit the data that well. For example, if the purple dots form a curve, a line can only do so well at making a decision boundary. This is why we try to pick a model that will be able to form a good decision boundary on the data we're using.\n",
    "\n",
    "Let's go back to the `classification_data`, `blobs_data`, and `circle_data` datasets. Consider the shape of the data in each dataset, and try to pick a model from the ones you explored above that you think will fit each dataset well. Don't forget to use `train_test_split` on each new dataset!\n",
    "### `classification_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up X, y, X_train, X_test, y_train, and y_test like you did above, but using classification_data\n",
    "# Use a random state of 123. 30% of the data should be in the test set\n",
    "#\n",
    "# HINT: Make sure that your X_train, X_test... etc variables are in the right order\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Test case (DO NOT EDIT)\n",
    "assert len(X_train) + len(X_test) == len(X), \"Expected X_train and X_test to combine to X\"\n",
    "assert len(y_train) + len(y_test) == len(y), \"Expected y_train and y_test to combine to y\"\n",
    "assert len(X_train) == len(X)*0.7, \"Expected X_train to be 70% of X's size, got \" + str(100*len(X_train)/len(X)) + \"%\"\n",
    "assert len(X_test) == len(X)*0.3, \"Expected X_test to be 30% of X's size, got \" + str(100*len(X_test)/len(X)) + \"%\"\n",
    "assert len(y_train) == len(y)*0.7, \"Expected y_train to be 70% of y's size, got \" + str(100*len(y_train)/len(y)) + \"%\"\n",
    "assert len(y_test) == len(y)*0.3, \"Expected y_test to be 30% of y's size, got \" + str(100*len(y_test)/len(y)) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try out a model, fit it to the training data, and score it with the testing data. If a random state is needed, use 42\n",
    "#\n",
    "# HINT: Don't forget to modify the hyperparameter(s)! Play with them to see if you can find the best value for each.\n",
    "# HINT: If your code isn't working because of an array reshaping issue, you might not have split the data correctly above.\n",
    "#       Try changing that and running this cell again.\n",
    "# TIP: You can train more than one model to see which one works best! Add a new cell or create new models below.\n",
    "#\n",
    "\n",
    "classification_model = ...\n",
    "\n",
    "# use .fit(training data)\n",
    "# ...\n",
    "\n",
    "# use .score(testing data)\n",
    "classification_score = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment the code below to display the decision boundary\n",
    "# This may take a minute to run, depending on the model you picked\n",
    "# visualize_boundary(X_test, y_test, classification_model, classification_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `blobs_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up X, y, X_train, X_test, y_train, and y_test like you did above, but using blobs_data\n",
    "# Use a random state of 123. 30% of the data should be in the test set\n",
    "#\n",
    "# HINT: Make sure that your X_train, X_test... etc variables are in the right order\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Test case (DO NOT EDIT)\n",
    "assert len(X_train) + len(X_test) == len(X), \"Expected X_train and X_test to combine to X\"\n",
    "assert len(y_train) + len(y_test) == len(y), \"Expected y_train and y_test to combine to y\"\n",
    "assert len(X_train) == len(X)*0.7, \"Expected X_train to be 70% of X's size, got \" + str(100*len(X_train)/len(X)) + \"%\"\n",
    "assert len(X_test) == len(X)*0.3, \"Expected X_test to be 30% of X's size, got \" + str(100*len(X_test)/len(X)) + \"%\"\n",
    "assert len(y_train) == len(y)*0.7, \"Expected y_train to be 70% of y's size, got \" + str(100*len(y_train)/len(y)) + \"%\"\n",
    "assert len(y_test) == len(y)*0.3, \"Expected y_test to be 30% of y's size, got \" + str(100*len(y_test)/len(y)) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try out a model, fit it to the training data, and score it with the testing data. If a random state is needed, use 42\n",
    "#\n",
    "# HINT: Don't forget to modify the hyperparameter(s)! Play with them to see if you can find the best value for each.\n",
    "# HINT: If your code isn't working because of an array reshaping issue, you might not have split the data correctly above.\n",
    "#       Try changing that and running this cell again.\n",
    "# TIP: You can train more than one model to see which one works best! Add a new cell or create new models below.\n",
    "#\n",
    "\n",
    "blobs_model = ...\n",
    "\n",
    "# use .fit(training data)\n",
    "# ...\n",
    "\n",
    "# use .score(testing data)\n",
    "blobs_score = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment the code below to display the decision boundary\n",
    "# This may take a minute to run, depending on the model you picked\n",
    "# visualize_boundary(X_test, y_test, blobs_model, blobs_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `circle_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up X, y, X_train, X_test, y_train, and y_test like you did above, but using circle_data\n",
    "# Use a random state of 123. 30% of the data should be in the test set\n",
    "#\n",
    "# HINT: Make sure that your X_train, X_test... etc variables are in the right order\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Test case (DO NOT EDIT)\n",
    "assert len(X_train) + len(X_test) == len(X), \"Expected X_train and X_test to combine to X\"\n",
    "assert len(y_train) + len(y_test) == len(y), \"Expected y_train and y_test to combine to y\"\n",
    "assert len(X_train) == len(X)*0.7, \"Expected X_train to be 70% of X's size, got \" + str(100*len(X_train)/len(X)) + \"%\"\n",
    "assert len(X_test) == len(X)*0.3, \"Expected X_test to be 30% of X's size, got \" + str(100*len(X_test)/len(X)) + \"%\"\n",
    "assert len(y_train) == len(y)*0.7, \"Expected y_train to be 70% of y's size, got \" + str(100*len(y_train)/len(y)) + \"%\"\n",
    "assert len(y_test) == len(y)*0.3, \"Expected y_test to be 30% of y's size, got \" + str(100*len(y_test)/len(y)) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try out a model, fit it to the training data, and score it with the testing data. If a random state is needed, use 42\n",
    "#\n",
    "# HINT: Don't forget to modify the hyperparameter(s)! Play with them to see if you can find the best value for each.\n",
    "# HINT: If your code isn't working because of an array reshaping issue, you might not have split the data correctly above.\n",
    "#       Try changing that and running this cell again.\n",
    "# TIP: You can train more than one model to see which one works best! Add a new cell or create new models below.\n",
    "#\n",
    "\n",
    "circle_model = ...\n",
    "\n",
    "# use .fit(training data)\n",
    "# ...\n",
    "\n",
    "# use .score(testing data)\n",
    "circle_score = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment the code below to display the decision boundary\n",
    "# This may take a minute to run, depending on the model you picked\n",
    "# visualize_boundary(X_test, y_test, circle_model, circle_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "MLR_sYAnfGWM",
    "SlV9JkDS9d9C",
    "TZ7WlpCVlURO",
    "arJ8mn0Flc6W",
    "owI1bnnLe5yj",
    "HdjFxIfEfP7_",
    "_2jmJi8k-TA1",
    "41-VYO65-XdM",
    "a-E0-UTX-ZZt",
    "-IlIkO6v-bO3",
    "mH2r5fGle1yF",
    "bLEoUgL1MOKi",
    "MS93VIQaMyP3"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330] *",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
