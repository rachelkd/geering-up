{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZBrrEyZOsn6"
   },
   "source": [
    "## Setup stuff (don't edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uHE7HhLZ6utW"
   },
   "outputs": [],
   "source": [
    "# basic imports for libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# model imports\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "# evaluation and training imports\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# preprocessing imports\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DbO3QsY16yik",
    "outputId": "f48850a1-8bc8-4925-a8c9-f337c16304fe"
   },
   "outputs": [],
   "source": [
    "# install required package\n",
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "14WaIppBOSeK"
   },
   "outputs": [],
   "source": [
    "# import additional requirements\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IJRzecjxiXoo"
   },
   "outputs": [],
   "source": [
    "# create data folder\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sa02pHDf2-3A",
    "outputId": "c1fb2a7c-ef5f-4575-d1b3-883a9e16ca0b"
   },
   "outputs": [],
   "source": [
    "# fetch dataset\n",
    "adult = fetch_ucirepo(id=2)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X_adult = adult.data.features\n",
    "y_adult = adult.data.targets\n",
    "\n",
    "# minor preprocessing for the target (classes should only be <=50k and >50k)\n",
    "y_adult['income'] = y_adult['income'].map({\"<=50K.\": \"<=50K\", \">50K.\": \">50K\",\n",
    "                                           \"<=50K\": \"<=50K\", \">50K\": \">50K\"})\n",
    "\n",
    "# drop problematic columns, repetitive columns and ID column\n",
    "X_adult = X_adult.drop(columns=[\"race\", \"fnlwgt\", \"education-num\", \"sex\"])\n",
    "\n",
    "# ensure all null values as represented as NaN\n",
    "X_adult = X_adult.replace(\"?\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dDunhopk2_V_"
   },
   "outputs": [],
   "source": [
    "# Create dataset for both features and targets\n",
    "adult_data = pd.concat([X_adult, y_adult], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pc8sY5-5qOeZ"
   },
   "source": [
    "# Section 1: California Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "krj8ZRd26nLj",
    "outputId": "881aae10-a097-4804-fd4a-15fbcf68fa42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>-121.09</td>\n",
       "      <td>39.48</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>1.5603</td>\n",
       "      <td>78100.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>-121.21</td>\n",
       "      <td>39.49</td>\n",
       "      <td>18.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2.5568</td>\n",
       "      <td>77100.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>-121.22</td>\n",
       "      <td>39.43</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2254.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>1.7000</td>\n",
       "      <td>92300.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>-121.32</td>\n",
       "      <td>39.43</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>1.8672</td>\n",
       "      <td>84700.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>-121.24</td>\n",
       "      <td>39.37</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2785.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>2.3886</td>\n",
       "      <td>89400.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0        -122.23     37.88                41.0        880.0           129.0   \n",
       "1        -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2        -122.24     37.85                52.0       1467.0           190.0   \n",
       "3        -122.25     37.85                52.0       1274.0           235.0   \n",
       "4        -122.25     37.85                52.0       1627.0           280.0   \n",
       "...          ...       ...                 ...          ...             ...   \n",
       "20635    -121.09     39.48                25.0       1665.0           374.0   \n",
       "20636    -121.21     39.49                18.0        697.0           150.0   \n",
       "20637    -121.22     39.43                17.0       2254.0           485.0   \n",
       "20638    -121.32     39.43                18.0       1860.0           409.0   \n",
       "20639    -121.24     39.37                16.0       2785.0           616.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "0           322.0       126.0         8.3252            452600.0   \n",
       "1          2401.0      1138.0         8.3014            358500.0   \n",
       "2           496.0       177.0         7.2574            352100.0   \n",
       "3           558.0       219.0         5.6431            341300.0   \n",
       "4           565.0       259.0         3.8462            342200.0   \n",
       "...           ...         ...            ...                 ...   \n",
       "20635       845.0       330.0         1.5603             78100.0   \n",
       "20636       356.0       114.0         2.5568             77100.0   \n",
       "20637      1007.0       433.0         1.7000             92300.0   \n",
       "20638       741.0       349.0         1.8672             84700.0   \n",
       "20639      1387.0       530.0         2.3886             89400.0   \n",
       "\n",
       "      ocean_proximity  \n",
       "0            NEAR BAY  \n",
       "1            NEAR BAY  \n",
       "2            NEAR BAY  \n",
       "3            NEAR BAY  \n",
       "4            NEAR BAY  \n",
       "...               ...  \n",
       "20635          INLAND  \n",
       "20636          INLAND  \n",
       "20637          INLAND  \n",
       "20638          INLAND  \n",
       "20639          INLAND  \n",
       "\n",
       "[20640 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data = pd.read_csv(\"data/housing.csv\")\n",
    "housing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Em6wTYbFqZma"
   },
   "source": [
    "We can get a pretty good overview of the data just looking at it like this, but we can also use `.info()` and `.describe()` on a pandas DataFrame to learn some more about the data, and `.unique()` on a specific column to see all the values (in the case of a categorical feature, to see all the categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.569704</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>537.870553</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>206855.816909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.003532</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>421.385070</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>115395.615874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.800000</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1447.750000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563400</td>\n",
       "      <td>119600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.490000</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.534800</td>\n",
       "      <td>179700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.010000</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>4.743250</td>\n",
       "      <td>264725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
       "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
       "std        2.003532      2.135952           12.585558   2181.615252   \n",
       "min     -124.350000     32.540000            1.000000      2.000000   \n",
       "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
       "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
       "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
       "max     -114.310000     41.950000           52.000000  39320.000000   \n",
       "\n",
       "       total_bedrooms    population    households  median_income  \\\n",
       "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
       "mean       537.870553   1425.476744    499.539680       3.870671   \n",
       "std        421.385070   1132.462122    382.329753       1.899822   \n",
       "min          1.000000      3.000000      1.000000       0.499900   \n",
       "25%        296.000000    787.000000    280.000000       2.563400   \n",
       "50%        435.000000   1166.000000    409.000000       3.534800   \n",
       "75%        647.000000   1725.000000    605.000000       4.743250   \n",
       "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
       "\n",
       "       median_house_value  \n",
       "count        20640.000000  \n",
       "mean        206855.816909  \n",
       "std         115395.615874  \n",
       "min          14999.000000  \n",
       "25%         119600.000000  \n",
       "50%         179700.000000  \n",
       "75%         264725.000000  \n",
       "max         500001.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'ISLAND'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data.info()\n",
    "housing_data[\"ocean_proximity\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has:\n",
    "- 8 numerical features: `longitude`, `latitude`, `housing_median_age`, `total_rooms`, `total_bedrooms`, `population`, `households`, and `median_income`\n",
    "- 1 categorical feature: `ocean_proximity`, with the categories 'NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', and 'ISLAND'\n",
    "- the target variable: `median_house_value` - since this is a number, this is a _regression_ problem.\n",
    "\n",
    "Since the numerical features are all drastically bigger or smaller than each other, we will need to apply **scaling** to the data. We also have a categorical feature that we will need to handle with some kind of **encoding**. Also notice that the `total_bedrooms` feature has a lower count than the other features. This means that there are some missing values in that column! We'll need to apply **imputation**.\n",
    "\n",
    "Let's start by splitting our training and testing data. Drop the target column from the dataset to get `X` and `y`. **Let's also drop `ocean_proximity` and `total_bedrooms`, so we can focus entirely on scaling.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split housing_data into features (X) and target (y). Also drop ocean_proximity and total_bedrooms from the dataset\n",
    "#\n",
    "# HINT: use the pandas .drop() function\n",
    "# \n",
    "\n",
    "X = ...\n",
    "y = ...\n",
    "\n",
    "# TODO: Split housing_data into train and test sets. Use a random state of 123. 30% of the data should be in the test set\n",
    "# Then print out X_train and y_train below\n",
    "#\n",
    "# HINT: Make sure that your X_train, X_test... etc variables are in the right order\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a `KNeighborsRegressor` as our model. This model relies on measuring distances between points, so we should see a huge difference in score once scaling is applied. Before we scale, let's try to use the data as is. Use this documentation link to get familiar with `KNeighborsRegressor`. Feel free to play around with `n_neighbors` to improve the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train and score KNeighborsRegressor on the unscaled data\n",
    "#\n",
    "# HINT: Make sure that you use the American spelling of \"neighbors\"\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That initial score is pretty bad! Let's see how much scaling improves it.\n",
    "\n",
    "## Scaling \n",
    "Try both `MinMaxScaler` (documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)) and `StandardScaler` ([here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)) to see if one method is better than the other. Remember to use `fit_transform()` on the _training_ data and `transform()` on the _testing_ data to avoid breaking the golden rule. After scaling the data, try fitting and scoring the model again to see how much it improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use MinMaxScaler or StandardScaler to scale the data\n",
    "#\n",
    "\n",
    "scaler = ...\n",
    "X_train_scaled = ...\n",
    "X_test_scaled = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since preprocessors generally return NumPy arrays instead of pandas DataFrames, convert to DataFrame for easier reading\n",
    "# TODO: Uncomment the lines below to see your scaled data as DataFrames\n",
    "# X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns.to_list())\n",
    "# X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns.to_list())\n",
    "# X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train and score KNeighborsRegressor on the scaled data\n",
    "#\n",
    "# HINT: Make sure that you use the American spelling of \"neighbors\"\n",
    "# HINT: Make sure that you're using the scaled X_train and X_test\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better!\n",
    "\n",
    "## ColumnTransformer\n",
    "We've scaled the data, but we also want to apply encoding and imputation on it. There's a better way to do multiple preprocessing steps on the same dataset - a `ColumnTransformer`! To use the `ColumnTransformer` we need to specify:\n",
    "- Which preprocessor(s) we want to use (e.g. `StandardScaler`)\n",
    "- Which column(s) we want a particular preprocessor to modify (e.g. only numerical features)\n",
    "\n",
    "Fill in the lists below to sort the columns into numerical, categorical, and containing missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting X, y, X_train, X_test, y_train, and y_test\n",
    "X = housing_data.drop(columns=[\"median_house_value\"])\n",
    "y = housing_data[\"median_house_value\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill in the lists below with the appropriate feature names \n",
    "# The features are 'longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms',\n",
    "# 'population', 'households', 'median_income', and 'ocean_proximity'\n",
    "#\n",
    "# HINT: Features can be in one, many, or none of the lists\n",
    "\n",
    "numerical_features = ['longitude', ...]\n",
    "categorical_features = []\n",
    "missing_values_features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Features and Imputation\n",
    "There are two options to encode categorical features:\n",
    "- [`OrdinalEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html), which is best for _ordinal categorical features_. It will assign each category a number, e.g. small = 1, medium = 2, large = 3\n",
    "- [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), which is best for _nominal categorical features_. It will create a new column for each category and use 1s and 0s to represent membership in that category\n",
    "\n",
    "It is up to you to decide whether `OrdinalEncoder` or `OneHotEncoder` is a better fit for the `ocean_proximity` feature. Try both, by yourself or with a partner, and see which one produces a better score.\n",
    "\n",
    "## Imputation\n",
    "We will use [`SimpleImputer`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) to fill in the missing values in the `total_bedrooms` column.\n",
    "\n",
    "## Constructing the ColumnTransformer\n",
    "Assign one of `scaler`, `ordinal`, `one_hot`, or `imputer` to the `a`, `b`, and `c` variables below to fill in the correct steps of the ColumnTransformer. If you want to use `OrdinalEncoder` for `ocean_proximity`, change `ordered_categories` to be whichever order of categories you think is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Assign values to a, b, and c using scaler, ordinal, one_hot, and imputer, e.g. a = scaler\n",
    "# If you want to use OrdinalEncoder, change ordered_categories to the order you think is correct\n",
    "#\n",
    "# HINT: Think about which groups of features are being modified by a, b, and c, and in which order\n",
    "#\n",
    "\n",
    "ordered_categories = ['NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'ISLAND']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "ordinal = OrdinalEncoder(categories=[ordered_categories], dtype=int)\n",
    "one_hot = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "a = ...\n",
    "b = ...\n",
    "c = ...\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (make_pipeline (a, b), numerical_features),\n",
    "    (c, categorical_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the ColumnTransformer\n",
    "Now use the `ColumnTransformer` with `X_train` and `X_test` exactly as you did with the scalers. Remember to use `fit_transform()` on the _training_ data and `transform()` on the _testing_ data to avoid breaking the golden rule. After preprocessing the data, try fitting and scoring the model again to see how much it improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the ColumnTransformer to apply all the preprocessing steps to X_train and X_test\n",
    "#\n",
    "\n",
    "X_train_transformed = ...\n",
    "X_test_transformed = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since preprocessors generally return NumPy arrays instead of pandas DataFrames, convert to DataFrame for easier reading\n",
    "# TODO: Uncomment the lines below to see your preprocessed data as DataFrames\n",
    "# X_train_transformed = pd.DataFrame(data=X_train_transformed, columns=ct.get_feature_names_out(), index=X_train.index)\n",
    "# X_test_transformed = pd.DataFrame(data=X_test_transformed, columns=ct.get_feature_names_out(), index=X_test.index)\n",
    "# X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train and score KNeighborsRegressor on the preprocessed data\n",
    "#\n",
    "# HINT: Make sure that you use the American spelling of \"neighbors\"\n",
    "# HINT: Make sure that you're using the transformed X_train and X_test\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwiiP3-ktgDQ"
   },
   "source": [
    "A small improvement, but an improvement either way!\n",
    "\n",
    "# Section 2: Census Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "-gakIxE_2Z8w",
    "outputId": "c0ebff94-ee82-4dec-b303-68c7ae488a71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  education      marital-status  \\\n",
       "0       39         State-gov  Bachelors       Never-married   \n",
       "1       50  Self-emp-not-inc  Bachelors  Married-civ-spouse   \n",
       "2       38           Private    HS-grad            Divorced   \n",
       "3       53           Private       11th  Married-civ-spouse   \n",
       "4       28           Private  Bachelors  Married-civ-spouse   \n",
       "...    ...               ...        ...                 ...   \n",
       "48837   39           Private  Bachelors            Divorced   \n",
       "48838   64               NaN    HS-grad             Widowed   \n",
       "48839   38           Private  Bachelors  Married-civ-spouse   \n",
       "48840   44           Private  Bachelors            Divorced   \n",
       "48841   35      Self-emp-inc  Bachelors  Married-civ-spouse   \n",
       "\n",
       "              occupation    relationship  capital-gain  capital-loss  \\\n",
       "0           Adm-clerical   Not-in-family          2174             0   \n",
       "1        Exec-managerial         Husband             0             0   \n",
       "2      Handlers-cleaners   Not-in-family             0             0   \n",
       "3      Handlers-cleaners         Husband             0             0   \n",
       "4         Prof-specialty            Wife             0             0   \n",
       "...                  ...             ...           ...           ...   \n",
       "48837     Prof-specialty   Not-in-family             0             0   \n",
       "48838                NaN  Other-relative             0             0   \n",
       "48839     Prof-specialty         Husband             0             0   \n",
       "48840       Adm-clerical       Own-child          5455             0   \n",
       "48841    Exec-managerial         Husband             0             0   \n",
       "\n",
       "       hours-per-week native-country income  \n",
       "0                  40  United-States  <=50K  \n",
       "1                  13  United-States  <=50K  \n",
       "2                  40  United-States  <=50K  \n",
       "3                  40  United-States  <=50K  \n",
       "4                  40           Cuba  <=50K  \n",
       "...               ...            ...    ...  \n",
       "48837              36  United-States  <=50K  \n",
       "48838              40  United-States  <=50K  \n",
       "48839              50  United-States  <=50K  \n",
       "48840              40  United-States  <=50K  \n",
       "48841              60  United-States   >50K  \n",
       "\n",
       "[48842 rows x 11 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xOicEGGALnL"
   },
   "source": [
    "This dataset has the target variable \"income\", that can take one of two values: <=50k or >50k. It also includes a mix of numerical and categorical features, and may have missing values.\n",
    "\n",
    "It's your turn to do preprocessing from scratch! Use the code above and scikit-learn documentation to help you.\n",
    "\n",
    "## Exploratory Data Analysis (EDA)\n",
    "Use `.info()`, `.describe()`, and `.unique()` to learn more about the data. Identify what preprocessing steps need to be taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ph28ZshNAY6v",
    "outputId": "d823fd4f-27ad-4ff9-86d6-595cea85535a"
   },
   "outputs": [],
   "source": [
    "# TODO: Perform EDA!\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnhDN8e7AdAu"
   },
   "source": [
    "_TODO: Double-click on this cell and write here what you noticed and which preprocessing steps you need to do!_\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4HgqXarGtcv"
   },
   "source": [
    "## Splitting Training and Testing Data\n",
    "Split `adult_data` into `X` and `y`, and further split the data into training and testing sets using `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split adult_data into features (X) and target (y)\n",
    "#\n",
    "# HINT: use the pandas .drop() function\n",
    "# \n",
    "\n",
    "X = ...\n",
    "y = ...\n",
    "\n",
    "# TODO: Split adult_data into train and test sets. Use a random state of 123. 30% of the data should be in the test set\n",
    "# Then print out X_train and y_train below\n",
    "#\n",
    "# HINT: Make sure that your X_train, X_test... etc variables are in the right order\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Feature Types\n",
    "Fill in the lists below to sort the columns into numerical, ordinal, nominal/needing one-hot encoding, and containing missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "CDkNCDDPBfLp"
   },
   "outputs": [],
   "source": [
    "# TODO: Fill in the lists below with the appropriate feature names \n",
    "# The features are 'age', 'workclass', 'education', 'marital-status', 'occupation',\n",
    "# 'relationship', 'capital-gain', 'capital-loss', 'hours-per-week', and 'native-country'\n",
    "# For any ordinal features, also add a list with the ordered categories\n",
    "#\n",
    "# HINT: Features can be in one, many, or none of the lists\n",
    "\n",
    "ordinal_features = ['education', ...]\n",
    "one_hot_features = []\n",
    "numerical_features = []\n",
    "missing_values_features = []\n",
    "\n",
    "# Ordered education categories\n",
    "ordered_education = ['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th', '11th', '12th', 'HS-grad', 'Some-college', 'Assoc-voc', 'Assoc-acdm', 'Bachelors', 'Masters', 'Prof-school', 'Doctorate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tu8SMWACKJp2"
   },
   "source": [
    "## Making a ColumnTransformer\n",
    "Design a ColumnTransformer to handle each category of column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "KB9fTt_bLQTw",
    "outputId": "98c7d690-0350-4ac1-d822-d681234406f6"
   },
   "outputs": [],
   "source": [
    "# TODO: Make a ColumnTransformer to preprocess the data\n",
    "#\n",
    "# HINT: Think about which groups of features are being modified by which preprocessing steps and in which order\n",
    "#\n",
    "\n",
    "ct = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCg31oH5PQGM"
   },
   "source": [
    "## Applying the ColumnTransformer\n",
    "Now use the `ColumnTransformer` with `X_train` and `X_test`. Remember to use `fit_transform()` on the _training_ data and `transform()` on the _testing_ data to avoid breaking the golden rule. Then, try fitting and scoring a model with the transformed data, and tune the hyperparameters to optimize the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kYJsz8Y1QuGn",
    "outputId": "1d272083-4b5f-40f3-9d0b-6d94a5771db3"
   },
   "outputs": [],
   "source": [
    "# TODO: Use the ColumnTransformer to apply all the preprocessing steps to X_train and X_test\n",
    "#\n",
    "\n",
    "X_train_transformed = ...\n",
    "X_test_transformed = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since preprocessors generally return NumPy arrays instead of pandas DataFrames, convert to DataFrame for easier reading\n",
    "# TODO: Uncomment the lines below to see your preprocessed data as DataFrames\n",
    "# X_train_transformed = pd.DataFrame(data=X_train_transformed, columns=ct.get_feature_names_out(), index=X_train.index)\n",
    "# X_test_transformed = pd.DataFrame(data=X_test_transformed, columns=ct.get_feature_names_out(), index=X_test.index)\n",
    "# X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train and score a classification model of your choice on the preprocessed data\n",
    "# Try DecisionTreeClassifier, LogisticRegression, or KNeighborsClassifier\n",
    "#\n",
    "# HINT: Make sure that you're using the transformed X_train and X_test\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "WZBrrEyZOsn6"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330] *",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
